# -*- coding: utf-8 -*-
"""img_rec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1szJLY36uBKodHU0aF57o3WX0897YRNOQ
"""

!pip install fastbook

#hide
import fastbook
fastbook.setup_book()

"""# Zadanie minimum

Wykorzystamy przykład z [fastbook](https://github.com/fastai/fastbook/blob/master/02_production.ipynb):
"""

#hide
from fastbook import *
from fastai.vision.widgets import *

path = Path('//content/gdrive/MyDrive/archive')

loko = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=Resize(128))

#hide
dls = loko.dataloaders(path)

dls.valid.show_batch(max_n=8, nrows=1)

"""### Przygotowanie danych"""

loko = loko.new(item_tfms=RandomResizedCrop(96, min_scale=0.1))
dls = loko.dataloaders(path, bs=20)
dls.train.show_batch(max_n=8, nrows=1, unique=True)

"""### Data Augmentation"""

#hide
loko = loko.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=1.5))
dls = loko.dataloaders(path, bs=25)
dls.train.show_batch(max_n=8, nrows=2, unique=True)

"""### Trenowanie

Wykorzystamy istniejący model [rosnet18](https://fastai1.fast.ai/vision.models.html).
"""

learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(5) # można poeksperymentować

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

interp.plot_top_losses(4, nrows=1)

cleaner = ImageClassifierCleaner(learn)
cleaner

learn.export() # Eksport przetrenowanego modelu (może się przydać przy użytku w innym projekcie)

path = Path()
learn_inf = load_learner(path/'export.pkl') # import zapisanego wyżej modelu (tak dla zasady)

out_pl = widgets.Output()
out_pl.clear_output()
btn_upload = SimpleNamespace(data = ['/content/gdrive/MyDrive/archive/imgs_zip/imgs/Bugatti/Bugatti_000.jpg'])
img = PILImage.create(btn_upload.data[-1])
with out_pl: display(img.to_thumb(256,256))
btn_run = widgets.Button(description='Classify')
lbl_pred = widgets.Label()
lbl_pred.value = ""

def on_click_classify(change):
    img = PILImage.create(btn_upload.data[-1])
    pred,pred_idx,probs = learn_inf.predict(img)
    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'

def on_upload_change(change):
    img = PILImage.create(btn_upload.data[-1])
    out_pl.clear_output()
    with out_pl: display(img.to_thumb(256,256))

btn_run.on_click(on_click_classify)
btn_upload = widgets.FileUpload()
btn_upload.observe(on_upload_change, names='_counter')
VBox([widgets.Label("Let's find out how it works!"), btn_upload, btn_run, out_pl, lbl_pred])

"""#Prownanie fine tune vs manual freeze"""

car_data = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=Resize(128)
)

dls = car_data.dataloaders(path, bs=32)
dls.show_batch(max_n=9, figsize=(9,6))

# finetune_5
learn1 = cnn_learner(dls, resnet18, metrics=accuracy)
learn1.fine_tune(5)

# manual (freeze/unfreeze)
learn2 = cnn_learner(dls, resnet18, metrics=accuracy)

learn2.freeze()
learn2.fit_one_cycle(1, lr_max=3e-3)

learn2.unfreeze()
learn2.fit_one_cycle(4, lr_max=slice(1e-6,1e-4))

# porowanie
print("Strata – fine_tune:")
learn1.recorder.plot_loss()

print("Strata – ręczne freeze/unfreeze:")
learn2.recorder.plot_loss()

#porównanie dokładności
acc1 = learn1.validate()[1]
acc2 = learn2.validate()[1]

print(f" Dokładność fine_tune: {acc1:.4f}")
print(f" Dokładność freeze/unfreeze: {acc2:.4f}")

# macierze pomyłek (opcjonalnie)
interp1 = ClassificationInterpretation.from_learner(learn1)
interp1.plot_confusion_matrix(title='fine_tune')

interp2 = ClassificationInterpretation.from_learner(learn2)
interp2.plot_confusion_matrix(title='freeze/unfreeze')